{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libertem.common import Shape, Slice\n",
    "from libertem.udf.base import UDFMeta, UDFResults\n",
    "from libertem.common.buffers import BufferWrapper\n",
    "from libertem.io.dataset.base import DataSetMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libertem.udf.sum import SumUDF\n",
    "from libertem.udf.sumsigudf import SumSigUDF\n",
    "from libertem_live.detectors.k2is.proto import MySubProcess, SyncState, PlaceholderPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDataSet:\n",
    "    def __init__(self):\n",
    "        self.shape = Shape((num_frames, 1860, 2048), sig_dims=2)\n",
    "        self.dtype = np.uint16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeExecutor:\n",
    "    def run_tasks(self, tasks, cancel_id):\n",
    "        ss = SyncState(num_processes=len(tasks))\n",
    "        processes = []\n",
    "        oqs = []\n",
    "        try:\n",
    "            for i in tasks:\n",
    "                oq = mp.Queue()\n",
    "                p = MySubProcess(idx=i, sync_state=ss, udfs=udfs, out_queue=oq)\n",
    "                p.start()\n",
    "                processes.append(p)\n",
    "                oqs.append(oq)\n",
    "            for idx, q in enumerate(oqs):\n",
    "                print(f\"getting result from q {q} ({idx})\")\n",
    "                yield q.get(), idx\n",
    "        finally:\n",
    "            for p in processes:\n",
    "                p.join()\n",
    "\n",
    "    def ensure_sync(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_udf_tasks(dataset, roi, corrections, backends):\n",
    "    # in case of a k2is live dataset, we need to create \"tasks\" for each partition, so for each sector:\n",
    "    assert roi is None\n",
    "    assert corrections is None or not corrections.have_corrections()\n",
    "    \n",
    "    return list(range(8))\n",
    "    # raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_dtype(udfs, dtype, corrections):\n",
    "    if corrections is not None and corrections.have_corrections():\n",
    "        tmp_dtype = np.result_type(np.float32, dtype)\n",
    "    else:\n",
    "        tmp_dtype = dtype\n",
    "    for udf in udfs:\n",
    "        tmp_dtype = np.result_type(\n",
    "            udf.get_preferred_input_dtype(),\n",
    "            tmp_dtype\n",
    "        )\n",
    "    return tmp_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_run_for_dataset(\n",
    "    udfs, dataset, executor, roi, corrections, backends, dry\n",
    "):\n",
    "    meta = UDFMeta(\n",
    "        partition_shape=None,\n",
    "        dataset_shape=dataset.shape,\n",
    "        roi=roi,\n",
    "        dataset_dtype=dataset.dtype,\n",
    "        input_dtype=_get_dtype(udfs, dataset.dtype, corrections),\n",
    "        corrections=corrections,\n",
    "    )\n",
    "    for udf in udfs:\n",
    "        udf.set_meta(meta)\n",
    "        udf.init_result_buffers()\n",
    "        udf.allocate_for_full(dataset, roi)\n",
    "\n",
    "        if hasattr(udf, 'preprocess'):\n",
    "            udf.set_views_for_dataset(dataset)\n",
    "            udf.preprocess()\n",
    "    if dry:\n",
    "        tasks = []\n",
    "    else:\n",
    "        tasks = list(make_udf_tasks(dataset, roi, corrections, backends))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _partition_by_idx(idx):\n",
    "    # num_frames = 1800  # less than 10 seconds\n",
    "\n",
    "    meta = DataSetMeta(\n",
    "        shape=Shape((num_frames, 1860, 2048), sig_dims=2),\n",
    "        image_count=num_frames,\n",
    "        raw_dtype=np.uint16,\n",
    "    )\n",
    "\n",
    "    x_offset = 256 * idx\n",
    "    \n",
    "    partition_slice = Slice(\n",
    "        origin=(0, 0, x_offset),\n",
    "        shape=Shape((num_frames, 1860, 256), sig_dims=2),\n",
    "    )\n",
    "\n",
    "    # let's first create single partition per sector, with size >= what\n",
    "    # we expect during 10 seconds of runtime\n",
    "    return PlaceholderPartition(\n",
    "        meta=meta,\n",
    "        partition_slice=partition_slice,\n",
    "        tiles=[],\n",
    "        start_frame=0,\n",
    "        num_frames=num_frames,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_for_dataset_sync(udfs, dataset, executor,\n",
    "                    roi=None, progress=False, corrections=None, backends=None, dry=False):\n",
    "    tasks = _prepare_run_for_dataset(\n",
    "        udfs, dataset, executor, roi, corrections, backends, dry\n",
    "    )\n",
    "    cancel_id = str(uuid.uuid4())\n",
    "\n",
    "    if progress:\n",
    "        from tqdm import tqdm\n",
    "        t = tqdm(total=len(tasks))\n",
    "\n",
    "    executor = executor.ensure_sync()\n",
    "\n",
    "    damage = BufferWrapper(kind='nav', dtype=bool)\n",
    "    damage.set_shape_ds(dataset.shape, roi)\n",
    "    damage.allocate()\n",
    "    if tasks:\n",
    "        for part_results, task in executor.run_tasks(tasks, cancel_id):\n",
    "            if progress:\n",
    "                t.update(1)\n",
    "            for results, udf in zip(part_results, udfs):\n",
    "                udf.set_views_for_partition(_partition_by_idx(task))\n",
    "                udf.merge(\n",
    "                    dest=udf.results.get_proxy(),\n",
    "                    src=results.get_proxy()\n",
    "                )\n",
    "                udf.clear_views()\n",
    "            v = damage.get_view_for_partition(_partition_by_idx(task))\n",
    "            v[:] = True\n",
    "            yield UDFResults(\n",
    "                buffers=tuple(\n",
    "                    udf._do_get_results()\n",
    "                    for udf in udfs\n",
    "                ),\n",
    "                damage=damage\n",
    "            )\n",
    "    else:\n",
    "        # yield at least one result (which should be empty):\n",
    "        for udf in udfs:\n",
    "            udf.clear_views()\n",
    "        yield UDFResults(\n",
    "            buffers=tuple(\n",
    "                udf._do_get_results()\n",
    "                for udf in udfs\n",
    "            ),\n",
    "            damage=damage\n",
    "        )\n",
    "\n",
    "    if progress:\n",
    "        t.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-ending",
   "metadata": {},
   "source": [
    "# kind=\"sig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = 8\n",
    "ss = SyncState(num_processes=num_processes)\n",
    "processes = []\n",
    "oqs = []\n",
    "udfs = [SumUDF()]\n",
    "try:\n",
    "    for i in range(num_processes):\n",
    "        oq = mp.Queue()\n",
    "        p = MySubProcess(idx=i, sync_state=ss, udfs=udfs, out_queue=oq, acqtime=10)\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "        oqs.append(oq)\n",
    "\n",
    "        # because \n",
    "        time.sleep(15)\n",
    "        results = []\n",
    "        for q in oqs:\n",
    "            while not q.empty():\n",
    "                results.append(q.get())\n",
    "finally:\n",
    "    \n",
    "    for p in processes:\n",
    "        print(f\"joining process {p}\")\n",
    "        p.join()\n",
    "        print(f\"joined process {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(results[0][0].intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0 = oqs[0].get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-composite",
   "metadata": {},
   "source": [
    "# kind=\"nav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = 8\n",
    "ss = SyncState(num_processes=num_processes)\n",
    "processes = []\n",
    "oqs = []\n",
    "udfs = [SumSigUDF()]\n",
    "try:\n",
    "    for i in range(num_processes):\n",
    "        oq = mp.Queue()\n",
    "        p = MySubProcess(idx=i, sync_state=ss, udfs=udfs, out_queue=oq, acqtime=10)\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "        oqs.append(oq)\n",
    "finally:\n",
    "    for p in processes:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0 = oqs[0].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0[0].intensity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0sq = res0[0].intensity[:42*42].reshape((42, 42))\n",
    "print(res0sq[res0sq>0].min())\n",
    "plt.figure()\n",
    "plt.imshow(res0sq, vmin=3.317e8, vmax=res0sq.max())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0sq = res0[0].intensity[:3969].reshape((63, 63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(res0sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-phase",
   "metadata": {},
   "source": [
    "# run for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "udfs = [SumSigUDF()]\n",
    "ds = FakeDataSet()\n",
    "executor = FakeExecutor()\n",
    "for res in run_for_dataset_sync(udfs, dataset=ds, executor=executor):\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.buffers[0]['intensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0sq = res.buffers[0]['intensity'].data[:3969].reshape((63, 63))\n",
    "vmin = res0sq[res0sq != 0].min()\n",
    "vmax = res0sq[res0sq != 0].max()\n",
    "plt.figure()\n",
    "plt.imshow(res0sq[10:50, ...])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-petite",
   "metadata": {},
   "source": [
    "# run for dataset with kind='sig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "udfs = [SumUDF()]\n",
    "ds = FakeDataSet()\n",
    "executor = FakeExecutor()\n",
    "for res in run_for_dataset_sync(udfs, dataset=ds, executor=executor):\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(res.buffers[0]['intensity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-recovery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
